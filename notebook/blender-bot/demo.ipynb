{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running enviroment is NMT\n",
    "- https://mandgie.medium.com/how-to-build-your-own-chatbot-f5848ebcba8d\n",
    "- https://github.com/butyr/huggingface-transformer-chatbots/blob/main/src/chatbots/blenderbot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.51k/1.51k [00:00<00:00, 659kB/s]\n",
      "Downloading: 100%|██████████| 350M/350M [00:04<00:00, 72.4MB/s] \n",
      "Some weights of the model checkpoint at facebook/blenderbot_small-90M were not used when initializing BlenderbotSmallModel: ['lm_head.weight', 'final_logits_bias']\n",
      "- This IS expected if you are initializing BlenderbotSmallModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BlenderbotSmallModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Downloading: 100%|██████████| 964k/964k [00:00<00:00, 6.29MB/s]\n",
      "Downloading: 100%|██████████| 345k/345k [00:00<00:00, 2.79MB/s]\n",
      "Downloading: 100%|██████████| 205/205 [00:00<00:00, 155kB/s]\n",
      "Downloading: 100%|██████████| 99.0/99.0 [00:00<00:00, 37.2kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 3, 512]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BlenderbotSmallTokenizer, BlenderbotSmallModel\n",
    "\n",
    "model = BlenderbotSmallModel.from_pretrained(\"facebook/blenderbot_small-90M\",cache_dir=\"../cached\")\n",
    "tokenizer = BlenderbotSmallTokenizer.from_pretrained(\"facebook/blenderbot_small-90M\",cache_dir=\"../cached\")\n",
    "\n",
    "inputs = tokenizer(\"Studies have been shown that owning a dog is good for you\", return_tensors=\"pt\")\n",
    "decoder_inputs = tokenizer(\"Studies show that\", return_tensors=\"pt\")  # Batch size 1\n",
    "outputs = model(input_ids=inputs.input_ids, decoder_input_ids=decoder_inputs.input_ids)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "list(last_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.57k/1.57k [00:00<00:00, 959kB/s]\n",
      "Downloading: 100%|██████████| 730M/730M [00:09<00:00, 74.8MB/s] \n",
      "Downloading: 100%|██████████| 127k/127k [00:00<00:00, 1.50MB/s]\n",
      "Downloading: 100%|██████████| 62.9k/62.9k [00:00<00:00, 1.02MB/s]\n",
      "Downloading: 100%|██████████| 1.15k/1.15k [00:00<00:00, 639kB/s]\n",
      "Downloading: 100%|██████████| 16.0/16.0 [00:00<00:00, 12.4kB/s]\n",
      "Downloading: 100%|██████████| 772/772 [00:00<00:00, 315kB/s]\n",
      "/localscratch/chenboc1/anaconda3/envs/NMT/lib/python3.7/site-packages/transformers/generation_utils.py:1232: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 60 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"<s> That's unfortunate. Are they trying to lose weight or are they just trying to be healthier?</s>\"]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n",
    "\n",
    "mname = \"facebook/blenderbot-400M-distill\"\n",
    "model = BlenderbotForConditionalGeneration.from_pretrained(mname,cache_dir=\"../cached\")\n",
    "tokenizer = BlenderbotTokenizer.from_pretrained(mname,cache_dir=\"../cached\")\n",
    "UTTERANCE = \"My friends are cool but they eat too many carbs.\"\n",
    "inputs = tokenizer([UTTERANCE], return_tensors=\"pt\")\n",
    "reply_ids = model.generate(**inputs)\n",
    "print(tokenizer.batch_decode(reply_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human:  My friends are cool but they eat too many carbs.\n",
      "Bot:   That's unfortunate. Are they trying to lose weight or are they just trying to be healthier?\n",
      "Human:  I'm not sure\n",
      "Bot:   That's too bad. Have you tried encouraging them to change their eating habits? \n"
     ]
    }
   ],
   "source": [
    "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n",
    "\n",
    "mname = \"facebook/blenderbot-400M-distill\"\n",
    "model = BlenderbotForConditionalGeneration.from_pretrained(mname,cache_dir=\"../cached\")\n",
    "tokenizer = BlenderbotTokenizer.from_pretrained(mname,cache_dir=\"../cached\")\n",
    "UTTERANCE = \"My friends are cool but they eat too many carbs.\"\n",
    "print(\"Human: \", UTTERANCE)\n",
    "\n",
    "inputs = tokenizer([UTTERANCE], return_tensors=\"pt\")\n",
    "reply_ids = model.generate(**inputs)\n",
    "print(\"Bot: \", tokenizer.batch_decode(reply_ids, skip_special_tokens=True)[0])\n",
    "\n",
    "REPLY = \"I'm not sure\"\n",
    "print(\"Human: \", REPLY)\n",
    "\n",
    "NEXT_UTTERANCE = (\n",
    "    \"My friends are cool but they eat too many carbs.</s> <s>That's unfortunate. \"\n",
    "    \"Are they trying to lose weight or are they just trying to be healthier?</s> \"\n",
    "    \"<s> I'm not sure.\"\n",
    ")\n",
    "inputs = tokenizer([NEXT_UTTERANCE], return_tensors=\"pt\")\n",
    "next_reply_ids = model.generate(**inputs)\n",
    "print(\"Bot: \", tokenizer.batch_decode(next_reply_ids, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My friends are cool but they eat too many carbs.</s> <s>That's unfortunate. Are they trying to lose weight or are they just trying to be healthier?</s> <s> I'm not sure.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEXT_UTTERANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adapted from:\n",
    "https://mandgie.medium.com/how-to-build-your-own-chatbot-f5848ebcba8d\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from transformers import BlenderbotSmallTokenizer, BlenderbotSmallForConditionalGeneration\n",
    "import os\n",
    "\n",
    "\n",
    "class BlenderBot:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str ='facebook/blenderbot_small-90M',\n",
    "    ):\n",
    "        if not os.path.exists('./models/blenderbot'):\n",
    "            BlenderbotSmallForConditionalGeneration.from_pretrained(model_name).save_pretrained('./models/blenderbot')\n",
    "            BlenderbotSmallTokenizer.from_pretrained(model_name).save_pretrained('./models/blenderbot')\n",
    "\n",
    "        self.model = BlenderbotSmallForConditionalGeneration.from_pretrained('./models/blenderbot')\n",
    "        self.tokenizer = BlenderbotSmallTokenizer.from_pretrained('./models/blenderbot')\n",
    "\n",
    "    def __call__(self, inputs: str) -> str:\n",
    "        inputs_tokenized = self.tokenizer(inputs, return_tensors='pt')\n",
    "        reply_ids = self.model.generate(**inputs_tokenized)\n",
    "        reply = self.tokenizer.batch_decode(reply_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "        return reply\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            user_input = input(\"User: \")\n",
    "            print(\"Bot:\", self(user_input))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('NMT')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "700ab61d045a7459be8ea9d7886dc2db003f1a1678ca4cb3d1521822b075518e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
